{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pystan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-8e3d3900502f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStanModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcauchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pystan'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.stats.api as sms\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "from math import lgamma\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from pystan import StanModel\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde, cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./AdSmartABdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ef63-77a7-448b-bd1e-075f42c55e39</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000eabc5-17ce-4137-8efe-44734d914446</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>10</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile WebView</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00187412-2932-4542-a8ef-3633901c98d9</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Samsung SM-A705FN</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a7785-d3fe-4e11-a344-c8735acacc2c</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id experiment        date  hour  \\\n",
       "0  0008ef63-77a7-448b-bd1e-075f42c55e39    exposed  2020-07-10     8   \n",
       "1  000eabc5-17ce-4137-8efe-44734d914446    exposed  2020-07-07    10   \n",
       "2  0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "3  00187412-2932-4542-a8ef-3633901c98d9    control  2020-07-03    15   \n",
       "4  001a7785-d3fe-4e11-a344-c8735acacc2c    control  2020-07-03    15   \n",
       "\n",
       "          device_make  platform_os                browser  yes  no  response  \n",
       "0  Generic Smartphone            6          Chrome Mobile    0   0         2  \n",
       "1  Generic Smartphone            6          Chrome Mobile    0   0         2  \n",
       "2               E5823            6  Chrome Mobile WebView    0   1         0  \n",
       "3   Samsung SM-A705FN            6               Facebook    0   0         2  \n",
       "4  Generic Smartphone            6          Chrome Mobile    0   0         2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric: response\n",
    "Launch Criteria: Response should be yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile WebView</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>008aafdf-deef-4482-8fec-d98e3da054da</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>16</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00a1384a-5118-4d1b-925b-6cdada50318d</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00b6fadb-10bd-49e3-a778-290da82f7a8d</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>4</td>\n",
       "      <td>Samsung SM-A202F</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00ebf4a8-060f-4b99-93ac-c62724399483</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auction_id experiment        date  hour  \\\n",
       "2   0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "16  008aafdf-deef-4482-8fec-d98e3da054da    exposed  2020-07-04    16   \n",
       "20  00a1384a-5118-4d1b-925b-6cdada50318d    exposed  2020-07-06     8   \n",
       "23  00b6fadb-10bd-49e3-a778-290da82f7a8d    control  2020-07-08     4   \n",
       "27  00ebf4a8-060f-4b99-93ac-c62724399483    control  2020-07-03    15   \n",
       "\n",
       "           device_make  platform_os                browser  yes  no  response  \n",
       "2                E5823            6  Chrome Mobile WebView    0   1         0  \n",
       "16  Generic Smartphone            6          Chrome Mobile    1   0         1  \n",
       "20  Generic Smartphone            6          Chrome Mobile    0   1         0  \n",
       "23    Samsung SM-A202F            6               Facebook    1   0         1  \n",
       "27  Generic Smartphone            6          Chrome Mobile    0   1         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data.loc[~((data['yes']==0) &(data['no']==0))]\n",
    "data2['response']=np.where((data2.yes==1) & (data2.no==0),1,np.where((data2.yes==0) & (data2.no==1),0,2))\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile WebView</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>008aafdf-deef-4482-8fec-d98e3da054da</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>16</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00a1384a-5118-4d1b-925b-6cdada50318d</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00b6fadb-10bd-49e3-a778-290da82f7a8d</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>4</td>\n",
       "      <td>Samsung SM-A202F</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00ebf4a8-060f-4b99-93ac-c62724399483</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auction_id experiment        date  hour  \\\n",
       "2   0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "16  008aafdf-deef-4482-8fec-d98e3da054da    exposed  2020-07-04    16   \n",
       "20  00a1384a-5118-4d1b-925b-6cdada50318d    exposed  2020-07-06     8   \n",
       "23  00b6fadb-10bd-49e3-a778-290da82f7a8d    control  2020-07-08     4   \n",
       "27  00ebf4a8-060f-4b99-93ac-c62724399483    control  2020-07-03    15   \n",
       "\n",
       "           device_make  platform_os                browser  yes  no  response  \n",
       "2                E5823            6  Chrome Mobile WebView    0   1         0  \n",
       "16  Generic Smartphone            6          Chrome Mobile    1   0         1  \n",
       "20  Generic Smartphone            6          Chrome Mobile    0   1         0  \n",
       "23    Samsung SM-A202F            6               Facebook    1   0         1  \n",
       "27  Generic Smartphone            6          Chrome Mobile    0   1         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data.loc[~((data['yes']==0) & (data['no']==0))]\n",
    "data2['response']=np.where((data2.yes==1) & (data2.no==0),1,np.where((data2.yes==0) & (data2.no==1),0,2))\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split of control users saw dummy ads vs exposed users who saw new ads:  47.14 %  52.86 %\n",
      "Number of control users who converted on old page:  264\n",
      "Percentage of control users who converted:  45.05 %\n",
      "Number of treatment users who converted on new page:  308\n",
      "Percentage of treatment users who converted:  46.88 %\n"
     ]
    }
   ],
   "source": [
    "#Show the % split between users\n",
    "#Calculate pooled probability\n",
    "mask = (data2[\"experiment\"] == \"control\")\n",
    "conversions_control = data2[\"response\"][mask].sum()\n",
    "total_users_control = data2[\"response\"][mask].count()\n",
    "\n",
    "mask = (data2[\"experiment\"] == \"exposed\")\n",
    "conversions_treatment = data2[\"response\"][mask].sum()\n",
    "total_users_treatment = data2[\"response\"][mask].count()\n",
    "\n",
    "print(\"Split of control users saw dummy ads vs exposed users who saw new ads: \", \n",
    "          round(total_users_control / data2[\"response\"].count() * 100, 2), \"% \",\n",
    "          round((total_users_treatment / data2[\"response\"].count()) * 100, 2), \"%\")\n",
    "\n",
    "#count number of users who converted in each group\n",
    "print(\"Number of control users who converted on old page: \", conversions_control)\n",
    "print(\"Percentage of control users who converted: \", round((conversions_control / total_users_control) * 100, 2), \"%\")\n",
    "\n",
    "mask = (data2[\"experiment\"] == \"treatment\")\n",
    "print(\"Number of treatment users who converted on new page: \", conversions_treatment)\n",
    "print(\"Percentage of treatment users who converted: \", round((conversions_treatment/ total_users_treatment) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversions_control\n",
    "total_users_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size:  5000000.0  per group\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Check what sample size is required\n",
    "baseline_rate = conversions_control / total_users_control\n",
    "practical_significance = 0.01 #user defined\n",
    "confidence_level = 0.05 #user defined, for a 95% confidence interval\n",
    "sensitivity = 1 #user defined\n",
    "\n",
    "effect_size = sms.proportion_effectsize(baseline_rate, baseline_rate + practical_significance)\n",
    "sample_size = sms.NormalIndPower().solve_power(effect_size = effect_size, power = sensitivity, \n",
    "                                               alpha = confidence_level, ratio=1)\n",
    "print(\"Required sample size: \", (sample_size), \" per group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_A = data[data.experiment == 'control']\n",
    "test_data_B = data[data.experiment == 'exposed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the metrics:- Calculating totals\n",
    "test_summary1 = data2.groupby('experiment').agg({\n",
    "    'response':'sum'\n",
    "})\n",
    "#Summarize the metrics:- Calculating means\n",
    "test_summary2= data2.groupby('experiment').agg({\n",
    "    'response':'mean'\n",
    "})\n",
    "test_summary1=test_summary1.T\n",
    "test_summary2=test_summary2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-51-3277d28732a9>\"\u001b[1;36m, line \u001b[1;32m271\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    func = eval(options.func)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    C:\\Users\\Hp\\AppData\\Roaming\\jupyter\\runtime\\kernel-777ce196-cedc-4f07-a561-0ed09993e7f2.json\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sims = 1000\n",
    "days = 20\n",
    "\n",
    "\n",
    "def get_snapshot(dat, start_time):\n",
    "    snapshot = dat[dat.time < start_time]\n",
    "    aggregated = snapshot.groupby(['response', 'experiment']).mean().reset_index()\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def readSimulationData(sim):\n",
    "    dat = pd.read_csv(\"../data/simulation/simulation\" + str(sim) + \".csv\")\n",
    "    return dat\n",
    "\n",
    "\n",
    "def pooled_std(std1, n1, std2, n2):\n",
    "    \"\"\"\n",
    "    Returns the pooled estimate of standard deviation. Assumes that population\n",
    "    variances are equal (std(v1)**2==std(v2)**2) - this assumption is checked\n",
    "    for reasonableness and an exception is raised if this is strongly violated.\n",
    "    Args:\n",
    "        std1 (float): standard deviation of first sample\n",
    "        n1 (integer): size of first sample\n",
    "        std2 (float): standard deviation of second sample\n",
    "        n2 (integer): size of second sample\n",
    "    Returns:\n",
    "        float: Pooled standard deviation\n",
    "    For further information visit:\n",
    "        http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Confidence_Intervals/BS704_Confidence_Intervals5.html\n",
    "    Todo:\n",
    "        Also implement a version for unequal variances.\n",
    "    \"\"\"\n",
    "    return np.sqrt(((n1 - 1) * std1 ** 2 + (n2 - 1) * std2 ** 2) / (n1 + n2 - 2))\n",
    "\n",
    "\n",
    "def normal_difference(mean1, std1, n1, mean2, std2, n2, percentiles=[2.5, 97.5],\n",
    "                      relative=False):\n",
    "    \"\"\"\n",
    "    Calculates the difference distribution of two normal distributions.\n",
    "    Computation is done in form of treatment minus control. It is assumed that\n",
    "    the standard deviations of both distributions do not differ too much.\n",
    "    Args:\n",
    "        mean1 (float): mean value of the treatment distribution\n",
    "        std1 (float): standard deviation of the treatment distribution\n",
    "        n1 (integer): number of samples of the treatment distribution\n",
    "        mean2 (float): mean value of the control distribution\n",
    "        std2 (float): standard deviation of the control distribution\n",
    "        n2 (integer): number of samples of the control distribution\n",
    "        percentiles (list): list of percentile values to compute\n",
    "        relative (boolean): If relative==True, then the values will be returned\n",
    "            as distances below and above the mean, respectively, rather than the\n",
    "            absolute values. In\tthis case, the interval is mean-ret_val[0] to\n",
    "            mean+ret_val[1]. This is more useful in many situations because it\n",
    "            corresponds with the sem() and std() functions.\n",
    "    Returns:\n",
    "        dict: percentiles and corresponding values\n",
    "    For further information vistit:\n",
    "            http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Confidence_Intervals/BS704_Confidence_Intervals5.html\n",
    "    \"\"\"\n",
    "    # Compute combined parameters from individual parameters\n",
    "    mean = mean1 - mean2\n",
    "    std = pooled_std(std1, n1, std2, n2)\n",
    "    # Computing standard error\n",
    "    st_error = std * np.sqrt(1. / n1 + 1. / n2)\n",
    "    # Computing degrees of freedom\n",
    "    d_free = n1 + n2 - 2\n",
    "\n",
    "    # Mapping percentiles via standard error\n",
    "    if relative:\n",
    "        return list([(p, stats.t.ppf(p / 100.0, df=d_free) * st_error)\n",
    "                     for p in percentiles])\n",
    "    else:\n",
    "        return list([(p, mean + stats.t.ppf(p / 100.0, df=d_free) * st_error)\n",
    "                     for p in percentiles])\n",
    "\n",
    "\n",
    "def HDI_from_MCMC(posterior_samples, credible_mass=0.95):\n",
    "    # Computes highest density interval from a sample of representative values,\n",
    "    # estimated as the shortest credible interval\n",
    "    # Takes Arguments posterior_samples (samples from posterior) and credible mass (normally .95)\n",
    "    # http://stackoverflow.com/questions/22284502/highest-posterior-density-region-and-central-credible-region\n",
    "    sorted_points = sorted(posterior_samples)\n",
    "    ciIdxInc = np.ceil(credible_mass * len(sorted_points)).astype('int')\n",
    "    nCIs = len(sorted_points) - ciIdxInc\n",
    "    ciWidth = [0] * nCIs\n",
    "    for i in range(0, nCIs):\n",
    "        ciWidth[i] = sorted_points[i + ciIdxInc] - sorted_points[i]\n",
    "    HDImin = sorted_points[ciWidth.index(min(ciWidth))]\n",
    "    HDImax = sorted_points[ciWidth.index(min(ciWidth)) + ciIdxInc]\n",
    "    return (HDImin, HDImax)\n",
    "\n",
    "\n",
    "# perform the fit\n",
    "def fit_stan(sm, df, kpi):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sm (pystan.model.StanModel): precompiled Stan model object\n",
    "        fit_data (dict): mapping between the observed data and the variable name\n",
    "    \n",
    "    Returns:\n",
    "        fit (StanFit4Model)\n",
    "        delta_trace (array)\n",
    "    \"\"\"\n",
    "    if 'normal' in kpi:\n",
    "        fit_data = {'Nc': sum(df.variant == 'A'),\n",
    "                    'Nt': sum(df.variant == 'B'),\n",
    "                    'x': df[kpi][df.variant == 'A'],\n",
    "                    'y': df[kpi][df.variant == 'B']}\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    fit = sm.sampling(data=fit_data, iter=2000, chains=4, n_jobs=1)\n",
    "\n",
    "    # extract the traces\n",
    "    traces = fit.extract()\n",
    "    return fit, traces\n",
    "\n",
    "\n",
    "def bayes_factor(stan_model, simulation_index, day_index, kpi):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sm (pystan.model.StanModel): precompiled Stan model object\n",
    "        simulation_index (int): random seed used for the simulation\n",
    "        day_index (int): time step of the peeking\n",
    "        kpi (str): KPI name\n",
    "    \n",
    "    Returns:\n",
    "        Bayes factor based on the Savage-Dickey density ratio\n",
    "    \"\"\"\n",
    "    print(\"simulation:\" + str(simulation_index) + \", day:\" + str(day_index))\n",
    "    dat = readSimulationData(simulation_index)\n",
    "    df = get_snapshot(dat, day_index + 1)\n",
    "\n",
    "    fit, traces = fit_stan(stan_model, df, kpi)\n",
    "    kde = gaussian_kde(traces['delta'])\n",
    "    hdi = HDI_from_MCMC(traces['delta'])\n",
    "    upper = hdi[1]\n",
    "    lower = hdi[0]\n",
    "    prior = cauchy.pdf(0, loc=0, scale=1)\n",
    "\n",
    "    bf_01 = kde.evaluate(0)[0] / prior\n",
    "    hdi_width = upper - lower\n",
    "    mean_delta = np.mean(traces['delta'])\n",
    "\n",
    "    significant_and_stop_bf = bf_01 < 1 / 3.\n",
    "    stop_bp = hdi_width < 0.08\n",
    "    significant_based_on_interval = 0 < lower or 0 > upper\n",
    "\n",
    "    return (simulation_index,\n",
    "            day_index,\n",
    "            bf_01,\n",
    "            significant_and_stop_bf,\n",
    "            hdi_width,\n",
    "            stop_bp,\n",
    "            mean_delta,\n",
    "            lower,\n",
    "            upper,\n",
    "            significant_based_on_interval)\n",
    "\n",
    "\n",
    "def group_sequential(simulation_index, day_index, kpi_name):\n",
    "    # calculated via obrien_fleming in ExpAn\n",
    "    # FIXME: use information fraction by samples instead of by days\n",
    "\n",
    "    alpha_new = [0.0, 5.7203197734168043e-10, 4.1792768579185235e-07, 1.1726446842441618e-05,\n",
    "                 8.8575438321303324e-05, 0.00034571958016904603, 0.00092319528256634698, 0.0019419129967408466,\n",
    "                 0.0034807996724293133, 0.005574596680784305, 0.0082219970554116006, 0.011396418465313252,\n",
    "                 0.015055713300509366, 0.019149643385582893, 0.023625121317601305, 0.028429630753072699,\n",
    "                 0.033513300693990944, 0.038830043164523653, 0.044338067953992866, 0.050000000000000044]\n",
    "\n",
    "    bounds = [8.0, 6.1979502959916175, 5.0606052474987155, 4.3826127028843844,\n",
    "              3.9199279690803821, 3.5783882874343131, 3.3129438012973726, 3.0989751615228083,\n",
    "              2.9217418019219434, 2.7718076486993621, 2.6428148976196288, 2.5303026237633186,\n",
    "              2.4310361262683289, 2.3426050275873065, 2.263171468152342, 2.1913063514414541,\n",
    "              2.1258794223717579, 2.0659834410152067, 2.0108806190046566, 1.959963984540054]\n",
    "\n",
    "    dat = readSimulationData(simulation_index)\n",
    "    kpi = get_snapshot(dat, day_index + 1)\n",
    "    ctrl = kpi.loc[kpi.variant == 'A', kpi_name]\n",
    "    treat = kpi.loc[kpi.variant == 'B', kpi_name]\n",
    "    mu_c = ctrl.mean()\n",
    "    mu_t = treat.mean()\n",
    "    sigma_c = ctrl.std()\n",
    "    sigma_t = treat.std()\n",
    "    n_c = len(ctrl)\n",
    "    n_t = len(treat)\n",
    "    z = (mu_t - mu_c) / np.sqrt(sigma_c ** 2 / n_c + sigma_t ** 2 / n_t)\n",
    "\n",
    "    if z > bounds[day_index] or z < -bounds[day_index]:\n",
    "        stop = True\n",
    "    else:\n",
    "        stop = False\n",
    "\n",
    "    mean_delta = mu_t - mu_c\n",
    "\n",
    "    interval = normal_difference(mu_c, sigma_c, n_c, mu_t, sigma_t, n_t,\n",
    "                                 [alpha_new[day_index] * 100 / 2, 100 - alpha_new[day_index] * 100 / 2])\n",
    "\n",
    "    lower = interval[0][1]\n",
    "    upper = interval[1][1]\n",
    "    significant_based_on_interval = 0 < lower or 0 > upper\n",
    "\n",
    "    return (simulation_index, day_index, stop, mean_delta, significant_based_on_interval)\n",
    "\n",
    "\n",
    "def run(func, cpus, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to run different simulations and write results to file.\n",
    "    \"\"\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    timestamp = '{:%Y%m%d}'.format(start_time)\n",
    "\n",
    "    if func.__name__ == 'bayes_factor':\n",
    "        stan_model = StanModel(file=kwargs['model_file'])\n",
    "        start_time_bf = datetime.datetime.now()\n",
    "        results = Parallel(n_jobs=int(cpus))(\n",
    "            delayed(func)(stan_model,\n",
    "                          s,\n",
    "                          d,\n",
    "                          kwargs['kpi'])\n",
    "            for s in range(sims) for d in range(days)\n",
    "        )\n",
    "        filename = func.__name__ + '/' + func.__name__ + '_' + kwargs['kpi'] + '_' + timestamp + '.csv'\n",
    "        end_time_bf = datetime.datetime.now()\n",
    "        bf_time_used = end_time_bf - start_time_bf\n",
    "        print(\"Bayes factor time spent in seconds:\" + str(bf_time_used.seconds))\n",
    "\n",
    "    elif func.__name__ == 'group_sequential':\n",
    "        results = Parallel(n_jobs=int(cpus))(\n",
    "            delayed(func)(s,\n",
    "                          d,\n",
    "                          kwargs['kpi'])\n",
    "            for s in range(sims) for d in range(days)\n",
    "        )\n",
    "        filename = func.__name__ + '/' + func.__name__ + '_' + kwargs['kpi'] + '_' + timestamp + '.csv'\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    time_used = end_time - start_time\n",
    "    print(\"All time spent in seconds:\" + str(time_used.seconds))\n",
    "\n",
    "    filename = '../output/' + filename\n",
    "    relativeBasedir = os.path.dirname(filename)\n",
    "    if not os.path.exists(relativeBasedir):\n",
    "        os.makedirs(relativeBasedir)\n",
    "\n",
    "    with open(filename, 'w+') as file_handler:\n",
    "        out = csv.writer(file_handler)\n",
    "        for item in results:\n",
    "            out.writerow(item)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = OptionParser()\n",
    "    parser.add_option(\"-c\", \"--cpu\", dest=\"cpu\",\n",
    "                      help=\"Number of CPUs to use, default=1\", default=1, type='int')\n",
    "    parser.add_option(\"-f\", \"--func\", dest=\"func\",\n",
    "                      help=\"Function that implements the stopping criteria\", type='str')\n",
    "    parser.add_option(\"-k\", \"--kpi\", dest=\"kpi\",\n",
    "                      help=\"Name of the KPI to be evaluated, default=normal_same\", default='normal_same', type='str')\n",
    "    parser.add_option(\"-m\", \"--model\", dest=\"model_file\",\n",
    "                      help=\"Precompiled Stan model file name\", default='', type='str')\n",
    "    parser.add_option(\"--distribution\", dest=\"distribution\",\n",
    "                      help=\"Type of the prior distribution\", default='cauchy', type='str')\n",
    "    parser.add_option(\"--scale\", dest=\"scale\",\n",
    "                      help=\"Scale parameter of the prior distribution\", default=1, type='float')\n",
    "    (options, args) = parser.parse_args()\n",
    "\n",
    "    func = eval(options.func)\n",
    "    run(func,\n",
    "        options.cpu,\n",
    "        model_file=options.model_file,\n",
    "        kpi=options.kpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hp\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-777ce196-cedc-4f07-a561-0ed09993e7f2.json'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group sequential testing\n",
    "Group sequential methods aim to perform statistical hypothesis tests at various time points before the predefined sample size is reached, while keeping the total false positive rate constant. It redistributes the error rate $\\alpha$ over time by a spending function. An $\\alpha$ spending function starts at 0 when the information fraction is 0 and reaches $\\alpha$ when the information fraction is 1, it can have arbitrary curvatures and two common forms are:\n",
    "\n",
    "O'Brien-Fleming (more conservative)\n",
    "Pocock\n",
    "Once the time-specific $\\alpha$s are calculated, they can then be converted to the z-score thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [8.000000, 8.000000, 8.000000, 4.915742, 4.336773, 3.942483, 3.638028, 3.394052, 3.193264, 3.024348, \n",
    "          2.879692, 2.753971, 2.643399, 2.545164, 2.457130, 2.377652, 2.305414, 2.239395, 2.178743, 2.122766]\n",
    "\n",
    "def gst(kpi_name):\n",
    "    zscore = pd.DataFrame()\n",
    "    overall_diff = [True]*sims\n",
    "    for i in range(sims):\n",
    "        dat = generate_random_data(i)\n",
    "        diff = [True]*days\n",
    "        # optional stopping\n",
    "        for d in range(days):\n",
    "            kpi = get_snapshot(dat, d+1)\n",
    "            ctrl = kpi.loc[kpi.variant=='A',kpi_name]\n",
    "            treat = kpi.loc[kpi.variant=='B',kpi_name]\n",
    "            mu_c = ctrl.mean()\n",
    "            mu_t = treat.mean()\n",
    "            sigma_c = ctrl.std()\n",
    "            sigma_t = treat.std()\n",
    "            n_c = len(ctrl)\n",
    "            n_t = len(treat)\n",
    "            z = (mu_t-mu_c) / np.sqrt(sigma_c**2/n_c+sigma_t**2/n_t)\n",
    "            \n",
    "            if z > bounds[d] or z < -bounds[d]:\n",
    "                diff[d] = True\n",
    "            else:\n",
    "                diff[d] = False\n",
    "                \n",
    "            zscore = zscore.append(pd.DataFrame({'z':z,'sim':i,'day':d,'delta':mu_t-mu_c,'significant':diff[d]},\n",
    "                                                index=[0]), ignore_index=True)\n",
    "                \n",
    "        if sum(diff) > 0:\n",
    "            overall_diff[i] = True\n",
    "        else:\n",
    "            overall_diff[i] = False\n",
    "\n",
    "    print('Difference detected: '+str(sum(overall_diff))+'/'+str(sims))\n",
    "    return zscore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data2['date']=pd.to_datetime(data['date'])\n",
    "\n",
    "ref_date=datetime.datetime(2020,7,3)\n",
    "day_count=[]\n",
    "for i in data2.index:\n",
    "    day_count.append(data2['date'].at[i].day-ref_date.day)\n",
    "data2['day_count']=day_count\n",
    "data2['time']=data2['day_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-eb3f0263e91e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mkpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_snapshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkpi_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'normal_same'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0minterval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'delta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'uplift_pctile'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'normal_same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Experiment' is not defined"
     ]
    }
   ],
   "source": [
    "overall_diff = [True]*sims\n",
    "for i in range(sims):\n",
    "    #dat = generate_random_data(i)\n",
    "    diff = [True]*days\n",
    "     # optional stoppin\n",
    "    for d in range(days):\n",
    "        kpi = get_snapshot(data2, d+1)\n",
    "        exp = Experiment('A', kpi, metadata)\n",
    "        res = exp.delta(kpi_subset=['normal_same'])\n",
    "        interval = res.statistic('delta', 'uplift_pctile', 'normal_same').loc[:,('value','B')]\n",
    "        if np.sign(interval[0])*np.sign(interval[1]) > 0:\n",
    "            diff[d] = True\n",
    "        else:\n",
    "            diff[d] = False\n",
    "        if sum(diff) > 0:\n",
    "            overall_diff[i] = True\n",
    "        else:\n",
    "            overall_diff[i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
